{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff4cdd3-80a6-4f49-b338-694a6f91af92",
   "metadata": {},
   "source": [
    "# Data\n",
    "start with a few tables first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c307e759-982d-4187-b8ab-fc1c2ea77199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/CrazyIdeas.csv\n",
      "(1000, 22)\n",
      "Index(['created_utc', 'score', 'domain', 'id', 'title', 'ups', 'downs',\n",
      "       'num_comments', 'permalink', 'selftext', 'link_flair_text', 'over_18',\n",
      "       'thumbnail', 'subreddit_id', 'edited', 'link_flair_css_class',\n",
      "       'author_flair_css_class', 'is_self', 'name', 'url', 'distinguished',\n",
      "       'subreddit'],\n",
      "      dtype='object')\n",
      "./data/3amjokes.csv\n",
      "(719, 22)\n",
      "Index(['created_utc', 'score', 'domain', 'id', 'title', 'ups', 'downs',\n",
      "       'num_comments', 'permalink', 'selftext', 'link_flair_text', 'over_18',\n",
      "       'thumbnail', 'subreddit_id', 'edited', 'link_flair_css_class',\n",
      "       'author_flair_css_class', 'is_self', 'name', 'url', 'distinguished',\n",
      "       'subreddit'],\n",
      "      dtype='object')\n",
      "./data/Beekeeping.csv\n",
      "(999, 22)\n",
      "Index(['created_utc', 'score', 'domain', 'id', 'title', 'ups', 'downs',\n",
      "       'num_comments', 'permalink', 'selftext', 'link_flair_text', 'over_18',\n",
      "       'thumbnail', 'subreddit_id', 'edited', 'link_flair_css_class',\n",
      "       'author_flair_css_class', 'is_self', 'name', 'url', 'distinguished',\n",
      "       'subreddit'],\n",
      "      dtype='object')\n",
      "./data/AskScienceFiction.csv\n",
      "(1000, 22)\n",
      "Index(['created_utc', 'score', 'domain', 'id', 'title', 'ups', 'downs',\n",
      "       'num_comments', 'permalink', 'selftext', 'link_flair_text', 'over_18',\n",
      "       'thumbnail', 'subreddit_id', 'edited', 'link_flair_css_class',\n",
      "       'author_flair_css_class', 'is_self', 'name', 'url', 'distinguished',\n",
      "       'subreddit'],\n",
      "      dtype='object')\n",
      "./data/DontPanic.csv\n",
      "(628, 22)\n",
      "Index(['created_utc', 'score', 'domain', 'id', 'title', 'ups', 'downs',\n",
      "       'num_comments', 'permalink', 'selftext', 'link_flair_text', 'over_18',\n",
      "       'thumbnail', 'subreddit_id', 'edited', 'link_flair_css_class',\n",
      "       'author_flair_css_class', 'is_self', 'name', 'url', 'distinguished',\n",
      "       'subreddit'],\n",
      "      dtype='object')\n",
      "./data/ShittyTechSupport.csv\n",
      "(763, 22)\n",
      "Index(['created_utc', 'score', 'domain', 'id', 'title', 'ups', 'downs',\n",
      "       'num_comments', 'permalink', 'selftext', 'link_flair_text', 'over_18',\n",
      "       'thumbnail', 'subreddit_id', 'edited', 'link_flair_css_class',\n",
      "       'author_flair_css_class', 'is_self', 'name', 'url', 'distinguished',\n",
      "       'subreddit'],\n",
      "      dtype='object')\n",
      "./data/Health.csv\n",
      "(1000, 22)\n",
      "Index(['created_utc', 'score', 'domain', 'id', 'title', 'ups', 'downs',\n",
      "       'num_comments', 'permalink', 'selftext', 'link_flair_text', 'over_18',\n",
      "       'thumbnail', 'subreddit_id', 'edited', 'link_flair_css_class',\n",
      "       'author_flair_css_class', 'is_self', 'name', 'url', 'distinguished',\n",
      "       'subreddit'],\n",
      "      dtype='object')\n",
      "Loaded 7 subreddits with 6109 total rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "path = './data' \n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "li = []\n",
    "for filename in all_files[:10]:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    \n",
    "    df['subreddit'] = filename.split('.')[0]\n",
    "    print(filename)\n",
    "    print(df.shape)\n",
    "    print(df.columns)\n",
    "    li.append(df)\n",
    "\n",
    "full_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"Loaded {len(all_files[:50])} subreddits with {len(full_df)} total rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924f7add-b493-4c30-a4c5-68395d0111df",
   "metadata": {},
   "source": [
    "# Threshold\n",
    "Since the entire dataset is already top 1000 posts, I'm just separating the top 10% or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ecf422-ac73-4e31-bbb9-f5bd4b842e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = full_df.groupby('subreddit')['score'].quantile(0.90).to_dict()\n",
    "\n",
    "\n",
    "full_df['threshold'] = full_df['subreddit'].map(thresholds)\n",
    "full_df['is_popular'] = (full_df['score'] >= full_df['threshold']).astype(int)\n",
    "\n",
    "\n",
    "full_df = full_df.drop(columns=['threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86beaa52-ae9c-44ee-9643-9f8a5acbaf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "over_18\n",
       "False    6091\n",
       "True       18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.groupby(['is_popular']).size()\n",
    "full_df.groupby(['over_18']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994f7174-3758-4409-b9fa-a840412fc4e7",
   "metadata": {},
   "source": [
    "# Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753db9c8-dc5b-48b1-991a-e90066f8bac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       14\n",
       "1       17\n",
       "2        4\n",
       "3       20\n",
       "4        4\n",
       "        ..\n",
       "6104    21\n",
       "6105    14\n",
       "6106    19\n",
       "6107     2\n",
       "6108     1\n",
       "Name: hour, Length: 6109, dtype: int32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['hour'] = pd.to_datetime(full_df['created_utc'], unit='s').dt.hour\n",
    "full_df['day_of_week'] = pd.to_datetime(full_df['created_utc'], unit='s').dt.dayofweek\n",
    "full_df['title_length'] = full_df['title'].str.len()\n",
    "full_df['is_question'] = full_df['title'].str.contains(r'\\?').astype(int)\n",
    "full_df['hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53f2fc7c-dfe8-4a60-8f5a-75de466dd949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_popular</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5498.0</td>\n",
       "      <td>76.599309</td>\n",
       "      <td>51.508032</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>611.0</td>\n",
       "      <td>102.122750</td>\n",
       "      <td>56.326562</td>\n",
       "      <td>10.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>302.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count        mean        std   min   25%   50%    75%    max\n",
       "is_popular                                                               \n",
       "0           5498.0   76.599309  51.508032   2.0  41.0  62.0   96.0  304.0\n",
       "1            611.0  102.122750  56.326562  10.0  63.0  92.0  130.0  302.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.groupby('is_popular')['title_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83399af-b824-4927-8833-c3030656c6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_popular\n",
       "0    0.433976\n",
       "1    0.058920\n",
       "Name: is_question, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.groupby('is_popular')['is_question'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3406b40-4b95-4a69-b3af-1ddde34e19fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>is_popular</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045653</td>\n",
       "      <td>0.039280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045653</td>\n",
       "      <td>0.047463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044016</td>\n",
       "      <td>0.031097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.046744</td>\n",
       "      <td>0.027823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039469</td>\n",
       "      <td>0.019640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.032739</td>\n",
       "      <td>0.026187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.025646</td>\n",
       "      <td>0.016367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.024191</td>\n",
       "      <td>0.016367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.019280</td>\n",
       "      <td>0.016367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.015096</td>\n",
       "      <td>0.016367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.024918</td>\n",
       "      <td>0.032733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.023827</td>\n",
       "      <td>0.040917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.038196</td>\n",
       "      <td>0.054010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.052565</td>\n",
       "      <td>0.081833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.054202</td>\n",
       "      <td>0.085106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.057112</td>\n",
       "      <td>0.072013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.056930</td>\n",
       "      <td>0.067103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.052019</td>\n",
       "      <td>0.072013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.054202</td>\n",
       "      <td>0.042553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.058021</td>\n",
       "      <td>0.052373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.052928</td>\n",
       "      <td>0.047463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.047472</td>\n",
       "      <td>0.044190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.045653</td>\n",
       "      <td>0.022913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.043470</td>\n",
       "      <td>0.027823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "is_popular         0         1\n",
       "hour                          \n",
       "0           0.045653  0.039280\n",
       "1           0.045653  0.047463\n",
       "2           0.044016  0.031097\n",
       "3           0.046744  0.027823\n",
       "4           0.039469  0.019640\n",
       "5           0.032739  0.026187\n",
       "6           0.025646  0.016367\n",
       "7           0.024191  0.016367\n",
       "8           0.019280  0.016367\n",
       "9           0.015096  0.016367\n",
       "10          0.024918  0.032733\n",
       "11          0.023827  0.040917\n",
       "12          0.038196  0.054010\n",
       "13          0.052565  0.081833\n",
       "14          0.054202  0.085106\n",
       "15          0.057112  0.072013\n",
       "16          0.056930  0.067103\n",
       "17          0.052019  0.072013\n",
       "18          0.054202  0.042553\n",
       "19          0.058021  0.052373\n",
       "20          0.052928  0.047463\n",
       "21          0.047472  0.044190\n",
       "22          0.045653  0.022913\n",
       "23          0.043470  0.027823"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(full_df['hour'], full_df['is_popular'], normalize='columns')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14438cc-0d30-4185-8281-bd687af27145",
   "metadata": {},
   "source": [
    "Sort data by time to simulate learning on old data to predict newer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b6c529d-cf15-4832-acfd-10688ca9066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.sort_values(by=['created_utc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "796c6492-5bc4-4770-bbe2-0ebb4d9d5785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4276 916 917\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['created_utc', 'score', 'domain', 'id', 'title', 'ups', 'downs',\n",
       "       'num_comments', 'permalink', 'selftext', 'link_flair_text', 'over_18',\n",
       "       'thumbnail', 'subreddit_id', 'edited', 'link_flair_css_class',\n",
       "       'author_flair_css_class', 'is_self', 'name', 'url', 'distinguished',\n",
       "       'subreddit', 'is_popular', 'hour', 'day_of_week', 'title_length',\n",
       "       'is_question'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = full_df.shape[0]\n",
    "\n",
    "train_end = int(0.70 * N)\n",
    "val_end   = int(0.85 * N)\n",
    "\n",
    "train_df = full_df.iloc[:train_end].copy()\n",
    "val_df   = full_df.iloc[train_end:val_end].copy()\n",
    "test_df  = full_df.iloc[val_end:].copy()\n",
    "\n",
    "print(len(train_df), len(val_df), len(test_df))\n",
    "print(train_df['created_utc'].max() < val_df['created_utc'].min())\n",
    "print(val_df['created_utc'].max() < test_df['created_utc'].min())\n",
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ade5d16-2f68-4109-a772-3178d6c4bfb5",
   "metadata": {},
   "source": [
    "# Select features and scale length of title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31c84fe2-1bfc-4847-b0a1-be6bc58ab9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_df['title_len_log'] = np.log1p(train_df['title_length'])\n",
    "val_df['title_len_log']   = np.log1p(val_df['title_length'])\n",
    "test_df['title_len_log']  = np.log1p(test_df['title_length'])\n",
    "\n",
    "X_train = train_df[['hour','is_question','is_self','title_len_log','selftext','title']]\n",
    "y_train = train_df['is_popular']\n",
    "\n",
    "X_val = val_df[['hour','is_question','is_self','title_len_log','selftext','title']]\n",
    "y_val = val_df['is_popular']\n",
    "\n",
    "X_test = test_df[['hour','is_question','is_self','title_len_log','selftext','title']]\n",
    "y_test = test_df['is_popular']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b525185b-ecc0-4d0c-84dd-0480c99ca953",
   "metadata": {},
   "source": [
    "# Fit model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a49a8960-93b0-46cc-af57-0e64e063c4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train pos rate: 0.09681945743685688\n",
      "val pos rate: 0.10698689956331878\n",
      "test pos rate: 0.1079607415485278\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.73      0.84       818\n",
      "           1       0.28      0.88      0.43        99\n",
      "\n",
      "    accuracy                           0.75       917\n",
      "   macro avg       0.63      0.80      0.63       917\n",
      "weighted avg       0.90      0.75      0.79       917\n",
      "\n",
      "Validation Precision@10%: 0.43956043956043955\n",
      "Test Precision@10%: 0.4810126582278481\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "print(\"train pos rate:\", y_train.mean())\n",
    "print(\"val pos rate:\", y_val.mean())\n",
    "print(\"test pos rate:\", y_test.mean())\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "val_probs = log_reg.predict_proba(X_val)[:, 1]\n",
    "test_probs = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "k = int(0.10 * len(val_probs))\n",
    "threshold = np.sort(val_probs)[-k]\n",
    "\n",
    "val_preds = (val_probs >= threshold).astype(int)\n",
    "val_precision = (val_preds[y_val == 1].sum()) / val_preds.sum()\n",
    "\n",
    "print(\"Validation Precision 10%:\", val_precision)\n",
    "\n",
    "test_preds = (test_probs >= threshold).astype(int)\n",
    "test_precision = (test_preds[y_test == 1].sum()) / test_preds.sum()\n",
    "\n",
    "print(\"Test Precision 10%:\", test_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3e5b5ab-3ffe-4e7b-9096-396e1add2539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour: 0.005\n",
      "is_question: -2.458\n",
      "is_self: 1.147\n",
      "title_len_log: 0.930\n"
     ]
    }
   ],
   "source": [
    "for name, coef in zip(X_train.columns, log_reg.coef_[0]):\n",
    "    print(f\"{name}: {coef:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba48b4e0-f58a-402b-96ce-cc657077f116",
   "metadata": {},
   "source": [
    "# XGBoost version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d71f3f1e-2a5a-4b6b-a05c-0d3be5de2ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.89      1106\n",
      "           1       0.29      0.65      0.40       116\n",
      "\n",
      "    accuracy                           0.82      1222\n",
      "   macro avg       0.63      0.74      0.65      1222\n",
      "weighted avg       0.89      0.82      0.85      1222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=500, stop_words='english')\n",
    "X_text = tfidf.fit_transform(full_df['title'])\n",
    "\n",
    "X_num = full_df[['hour', 'day_of_week', 'title_length', 'is_question']].values\n",
    "y = full_df['is_popular']\n",
    "\n",
    "X_combined = hstack([X_text, X_num])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = XGBClassifier(scale_pos_weight=9)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0800b8-432d-4046-8ec8-906e6d6f4267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kaggle)",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
